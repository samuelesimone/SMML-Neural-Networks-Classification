\chapter{Experiments} \label{ch:experiments}
Here the tables results for each experiment that I conducted:

\begin{longtable}{|c|c|c|c|c|c|}
\caption{First MLP training results for each fold and epoch} \\
\hline
Fold & Epoch & Loss & zero\_one\_loss\_func & Val\_Loss & Val\_zero\_one\_loss\_func \\
\hline
\endfirsthead

\multicolumn{6}{c}{{\tablename\ \thetable{} -- Continued from previous page}} \\
\hline
Fold & Epoch & Loss & zero\_one\_loss\_func & Val\_Loss & Val\_zero\_one\_loss\_func \\
\hline
\endhead

\hline
\multicolumn{6}{c}{{Continued on next page}} \\
\endfoot

\hline
\endlastfoot

1 & 1 & 841.5640 & 0.4819 & 0.7778 & 0.4574 \\
1 & 2 & 0.8091 & 0.4618 & 0.7777 & 0.4584 \\
1 & 3 & 0.7503 & 0.4589 & 0.7795 & 0.4584 \\
1 & 4 & 0.6898 & 0.4604 & 0.7803 & 0.4584 \\
1 & 5 & 7.5421 & 0.4615 & 0.7684 & 0.4564 \\
1 & 6 & 0.6897 & 0.4607 & 0.7778 & 0.4564 \\
1 & 7 & 0.6899 & 0.4607 & 0.7784 & 0.4564 \\
1 & 8 & 0.7288 & 0.4603 & 0.7786 & 0.4564 \\
1 & 9 & 0.6897 & 0.4609 & 0.7786 & 0.4564 \\
1 & 10 & 0.7136 & 0.4598 & 0.7782 & 0.4564 \\
\hline
2 & 1 & 920.0229 & 0.4724 & 0.7597 & 0.4522 \\
2 & 2 & 2.3125 & 0.4600 & 0.7584 & 0.4532 \\
2 & 3 & 0.7153 & 0.4623 & 0.6895 & 0.4522 \\
2 & 4 & 0.8337 & 0.4622 & 0.6886 & 0.4522 \\
2 & 5 & 0.6901 & 0.4614 & 0.6891 & 0.4522 \\
2 & 6 & 0.6899 & 0.4597 & 0.6890 & 0.4522 \\
2 & 7 & 0.6898 & 0.4609 & 0.6890 & 0.4522 \\
2 & 8 & 0.7029 & 0.4594 & 0.6890 & 0.4522 \\
2 & 9 & 0.6902 & 0.4620 & 0.6890 & 0.4522 \\
2 & 10 & 0.6903 & 0.4620 & 0.6890 & 0.4522 \\
\hline
3 & 1 & 593.7564 & 0.4803 & 0.6951 & 0.4432 \\
& 2 & 3.0590 & 0.4624 & 0.6904 & 0.4432 \\
& 3 & 0.6901 & 0.4641 & 0.6895 & 0.4432 \\
& 4 & 0.6900 & 0.4641 & 0.6889 & 0.4432 \\
& 5 & 0.7200 & 0.4620 & 0.6885 & 0.4432 \\
& 6 & 0.6898 & 0.4618 & 0.6882 & 0.4432 \\
& 7 & 0.6895 & 0.4647 & 0.6881 & 0.4432 \\
& 8 & 0.6907 & 0.4638 & 0.6880 & 0.4432 \\
& 9 & 0.6897 & 0.4641 & 0.6880 & 0.4432 \\
& 10 & 0.6901 & 0.4635 & 0.6880 & 0.4432 \\
\hline
4 & 1 & 907.8840 & 0.4852 & 0.7944 & 0.4707 \\
& 2 & 2.0251 & 0.4560 & 0.7090 & 0.4718 \\
& 3 & 0.6919 & 0.4543 & 0.7087 & 0.4707 \\
& 4 & 0.6900 & 0.4563 & 0.7087 & 0.4707 \\
& 5 & 0.6895 & 0.4548 & 0.7088 & 0.4707 \\
& 6 & 0.6896 & 0.4570 & 0.7089 & 0.4707 \\
& 7 & 0.6918 & 0.4550 & 0.7001 & 0.4697 \\
& 8 & 0.6896 & 0.4575 & 0.7002 & 0.4697 \\
& 9 & 0.6894 & 0.4560 & 0.7003 & 0.4697 \\
& 10 & 0.6893 & 0.4550 & 0.7003 & 0.4697 \\
\hline
5 & 1 & 830.7402 & 0.5075 & 0.6967 & 0.4719 \\
& 2 & 1.6454 & 0.4563 & 0.6913 & 0.4708 \\
& 3 & 0.8036 & 0.4571 & 0.6909 & 0.4708 \\
& 4 & 0.6914 & 0.4576 & 0.6907 & 0.4708 \\
& 5 & 0.6896 & 0.4563 & 0.6907 & 0.4708 \\
& 6 & 0.6895 & 0.4553 & 0.6908 & 0.4708 \\
& 7 & 0.6895 & 0.4560 & 0.6908 & 0.4708 \\
& 8 & 0.6892 & 0.4571 & 0.6909 & 0.4708 \\
& 9 & 0.6893 & 0.4566 & 0.6910 & 0.4708 \\
& 10 & 0.6893 & 0.4563 & 0.6910 & 0.4708 \\
\hline

\end{longtable}

\begin{longtable}{|c|c|c|c|c|c|}
\caption{First MLP after hypertraining results for each fold and epoch} \\
\hline
Fold & Epoch & Loss & zero\_one\_loss\_func & Val\_Loss & Val\_zero\_one\_loss\_func \\
\hline
\endfirsthead

\multicolumn{6}{c}{{\tablename\ \thetable{} -- Continued from previous page}} \\
\hline
Fold & Epoch & Loss & zero\_one\_loss\_func & Val\_Loss & Val\_zero\_one\_loss\_func \\
\hline
\endhead

\hline
\multicolumn{6}{c}{{Continued on next page}} \\
\endfoot

\hline
\endlastfoot
1 & 1 & 6402.9297 & 0.4792 & 0.6918 & 0.4755 \\
  & 2 & 20.6926 & 0.4580 & 0.6920 & 0.4755 \\
  & 3 & 6.5519 & 0.4575 & 0.6919 & 0.4755 \\
  & 4 & 4.8472 & 0.4567 & 0.6927 & 0.4755 \\
  & 5 & 7.7787 & 0.4554 & 0.6933 & 0.4755 \\
  & 6 & 6.7850 & 0.4577 & 0.6923 & 0.4755 \\
  & 7 & 6.2771 & 0.4549 & 0.6919 & 0.4755 \\
  & 8 & 3.6706 & 0.4567 & 0.6923 & 0.4755 \\
  & 9 & 3.5163 & 0.4559 & 0.6924 & 0.4755 \\
  & 10 & 2.6841 & 0.4552 & 0.6918 & 0.4755 \\
\hline
2 & 1 & 4105.2227 & 0.4698 & 0.6890 & 0.4460 \\
  & 2 & 18.9675 & 0.4612 & 0.6884 & 0.4460 \\
  & 3 & 9.2161 & 0.4670 & 0.6878 & 0.4460 \\
  & 4 & 7.5382 & 0.4630 & 0.6877 & 0.4460 \\
  & 5 & 2.5178 & 0.4637 & 0.6878 & 0.4460 \\
  & 6 & 4.8316 & 0.4659 & 0.6885 & 0.4460 \\
  & 7 & 1.9393 & 0.4645 & 0.6874 & 0.4460 \\
  & 8 & 3.9615 & 0.4638 & 0.6883 & 0.4460 \\
  & 9 & 1.3100 & 0.4636 & 0.6876 & 0.4460 \\
  & 10 & 2.0382 & 0.4631 & 0.6880 & 0.4460 \\
\hline
3 & 1 & 4279.5918 & 0.4742 & 0.6892 & 0.4533 \\
  & 2 & 13.3945 & 0.4664 & 0.6890 & 0.4533 \\
  & 3 & 4.3161 & 0.4611 & 0.6892 & 0.4533 \\
  & 4 & 9.3893 & 0.4650 & 0.6889 & 0.4533 \\
  & 5 & 3.5593 & 0.4632 & 0.6888 & 0.4533 \\
  & 6 & 3.7687 & 0.4584 & 0.6892 & 0.4533 \\
  & 7 & 1.6367 & 0.4630 & 0.6888 & 0.4533 \\
  & 8 & 1.7411 & 0.4600 & 0.6888 & 0.4533 \\
  & 9 & 1.7792 & 0.4611 & 0.6887 & 0.4533 \\
  & 10 & 1.8078 & 0.4595 & 0.6892 & 0.4533 \\
\hline
4 & 1 & 5847.2910 & 0.4888 & 0.7012 & 0.5255 \\
  & 2 & 18.9971 & 0.5070 & 0.6919 & 0.4745 \\
  & 3 & 0.9379 & 0.4684 & 0.6917 & 0.4745 \\
  & 4 & 0.6986 & 0.4563 & 0.6919 & 0.4745 \\
  & 5 & 0.6900 & 0.4560 & 0.6923 & 0.4745 \\
  & 6 & 0.6908 & 0.4555 & 0.6917 & 0.4745 \\
  & 7 & 0.6889 & 0.4552 & 0.6924 & 0.4745 \\
  & 8 & 0.6894 & 0.4565 & 0.6918 & 0.4745 \\
  & 9 & 0.8700 & 0.4573 & 0.6921 & 0.4745 \\
  & 10 & 0.6897 & 0.4575 & 0.6920 & 0.4745 \\
\hline
5 & 1 & 6920.2822 & 0.5217 & 0.7348 & 0.4537 \\
  & 2 & 0.7554 & 0.4621 & 0.6871 & 0.4537 \\
  & 3 & 0.7348 & 0.4623 & 0.6888 & 0.4537 \\
  & 4 & 0.8745 & 0.4623 & 0.6887 & 0.4537 \\
  & 5 & 0.6921 & 0.4608 & 0.6884 & 0.4537 \\
  & 6 & 0.6897 & 0.4608 & 0.6887 & 0.4537 \\
  & 7 & 0.6899 & 0.4608 & 0.6885 & 0.4537 \\
  & 8 & 0.6901 & 0.4630 & 0.6891 & 0.4537 \\
  & 9 & 0.6973 & 0.4605 & 0.6886 & 0.4537 \\
  & 10 & 0.6905 & 0.4633 & 0.6885 & 0.4537 \\
\hline
\label{table:mlp1hyp}
\end{longtable}

\begin{center}
\begin{longtable}{|c|c|c|c|c|c|}
\caption{CNN training results for each fold and epoch} \\
\hline
\textbf{Fold} & \textbf{Epoch} & \textbf{Loss} & \textbf{Zero-One Loss} & \textbf{Val Loss} & \textbf{Val Zero-One Loss} \\
\hline
1 & 1 & 0.6377 & 0.3554 & 0.5714 & 0.2873 \\
 & 2 & 0.5656 & 0.2574 & 0.5050 & 0.2379 \\
 & 3 & 0.5084 & 0.2201 & 0.4841 & 0.1914 \\
 & 4 & 0.4641 & 0.1962 & 0.4494 & 0.2269 \\
 & 5 & 0.4789 & 0.2112 & 0.5268 & 0.2297 \\
 & 6 & 0.4630 & 0.1944 & 0.3895 & 0.1577 \\
 & 7 & 0.4250 & 0.1747 & 0.3806 & 0.1577 \\
 & 8 & 0.4113 & 0.1712 & 0.3621 & 0.1494 \\
 & 9 & 0.4060 & 0.1697 & 0.4321 & 0.1792 \\
 & 10 & 0.4003 & 0.1707 & 0.3355 & 0.1320 \\
\hline
2 & 1 & 0.6440 & 0.3730 & 0.6200 & 0.3092 \\
 & 2 & 0.5646 & 0.2619 & 0.5208 & 0.2438 \\
 & 3 & 0.5163 & 0.2400 & 0.5359 & 0.2862 \\
 & 4 & 0.4898 & 0.2184 & 0.5103 & 0.2622 \\
 & 5 & 0.4666 & 0.2042 & 0.4583 & 0.1719 \\
 & 6 & 0.4564 & 0.1928 & 0.4790 & 0.2299 \\
 & 7 & 0.4502 & 0.1965 & 0.4241 & 0.1712 \\
 & 8 & 0.4152 & 0.1761 & 0.4199 & 0.1626 \\
 & 9 & 0.4045 & 0.1711 & 0.4113 & 0.1841 \\
 & 10 & 0.4077 & 0.1727 & 0.4501 & 0.2206 \\
\hline
3 & 1 & 0.6494 & 0.3746 & 0.5797 & 0.2698 \\
 & 2 & 0.5625 & 0.2673 & 0.5442 & 0.2747 \\
 & 3 & 0.5195 & 0.2351 & 0.4789 & 0.2098 \\
 & 4 & 0.4979 & 0.2179 & 0.4449 & 0.1910 \\
 & 5 & 0.4535 & 0.1954 & 0.4147 & 0.1535 \\
 & 6 & 0.4456 & 0.1936 & 0.4026 & 0.1653 \\
 & 7 & 0.4246 & 0.1732 & 0.3914 & 0.1639 \\
 & 8 & 0.4340 & 0.1847 & 0.3959 & 0.1566 \\
 & 9 & 0.4014 & 0.1629 & 0.4562 & 0.2286 \\
 & 10 & 0.3970 & 0.1678 & 0.3694 & 0.1549 \\
\hline
4 & 1 & 0.6432 & 0.3631 & 0.5496 & 0.2645 \\
 & 2 & 0.5696 & 0.2663 & 0.5117 & 0.1941 \\
 & 3 & 0.5180 & 0.2360 & 0.4826 & 0.1787 \\
 & 4 & 0.4866 & 0.2074 & 0.4352 & 0.1756 \\
 & 5 & 0.4693 & 0.2009 & 0.4211 & 0.1662 \\
 & 6 & 0.4525 & 0.1919 & 0.4434 & 0.2037 \\
 & 7 & 0.4295 & 0.1830 & 0.4131 & 0.1597 \\
 & 8 & 0.4221 & 0.1842 & 0.3998 & 0.1587 \\
 & 9 & 0.4010 & 0.1623 & 0.3793 & 0.1503 \\
 & 10 & 0.4030 & 0.1696 & 0.3813 & 0.1576 \\
\hline
5 & 1 & 0.6642 & 0.3964 & 0.6219 & 0.3389 \\
 & 2 & 0.5809 & 0.2812 & 0.5462 & 0.2440 \\
 & 3 & 0.5439 & 0.2500 & 0.5333 & 0.2583 \\
 & 4 & 0.5147 & 0.2266 & 0.4992 & 0.1932 \\
 & 5 & 0.4811 & 0.2050 & 0.4485 & 0.2135 \\
 & 6 & 0.4596 & 0.1990 & 0.4555 & 0.2094 \\
 & 7 & 0.4549 & 0.1940 & 0.4256 & 0.1764 \\
 & 8 & 0.4268 & 0.1753 & 0.5045 & 0.2706 \\
 & 9 & 0.4198 & 0.1791 & 0.4268 & 0.1660 \\
 & 10 & 0.4197 & 0.1801 & 0.4139 & 0.1847 \\
\hline
\label{table:cnn}
\end{longtable}
\end{center}



